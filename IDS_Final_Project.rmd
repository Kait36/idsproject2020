---
title: "<center>IDS-Final Project</center>"
author: "<center>Avisek Choudhury, Aldo Adriazola, Kait Arnold</center>"
date: "<center>3/08/2020</center>"
output:
  pdf_document: 
    toc: yes
  html_document: 
    toc: yes
---

## Dataset

The physicians have identified a data set that consists of over 500 measurements from Fine Needle Aspiration (FNA) of breast tissue masses. In an FNA, a small needle is used to extract a sample of cells from a tissue mass. The cells are then photographed under a microscope. The resulting photographs are entered into graphical imaging software. A trained technician uses a mouse pointer to draw the boundary of the nuclei. The software then calculates each of ten characteristics for the nuclei. This process is repeated for most or all of the nuclei in the sample.

The data consists of measurements of the cell nuclei for the following characteristics: 

1. radius 
2. texture 
3. perimete r
4. area 
5. smoothness (local variation in radius lengths) 
6. compactness (perimeter^2 / area - 1.0) 
7. concavity (severity of concave portions of the contour) 
8. concave points (number of concave portions of the contour) 
9. symmetry 
10. fractal dimension ("coastline approximation" - 1) 

Measurements of these ten characteristics are summarized for all cells in the sample. The dataset consists of the mean, standard error of the mean, and maximum of the 10 characteristics, for a total of 30 observations for each. Additionally, the data set includes an identification number and a variable that indicates if the tissue mass is malignant (M) or benign (B).

```{r readCSV, warning=FALSE, error=TRUE, message=FALSE}

#Load the necessary libraries
library(tidyverse)
library(class)
library(caret)
```


# 1. Download the data from NeXus: FNA_cancer.csv
```{r readCSV, warning=FALSE, error=TRUE, message=FALSE}
#Load the dataset that was previously downloaded
cancer_df <- read_csv('C:/MSDS/Spring 2020/IDS/Project/FNA_cancer.csv')

#Print the dataset
head(cancer_df)
```


# 2. Perform basic exploratory data analysis.

## Exploratory data analysis (EDA)

```{r combHist, warning=FALSE, error=TRUE, message=FALSE}

# ggplot(cancer_df[ , c(3:12)] %>% gather(), aes(value)) + 
#     geom_histogram(bins = 10) + 
#     facet_wrap(~key, scales = 'free_x')
# create a histogram for the mean measurements
ggplot(cancer_df[ , c(2:12)] %>% 
         pivot_longer(cols = radius_mean:fractal_dimension_mean), 
       aes(value, fill = diagnosis)) +
    geom_histogram(bins = 10) +  ggtitle("Histogram of Mean Measurements") +
  theme(plot.title = element_text(hjust = 0.5)) +
    facet_wrap(~name, scales = 'free_x')

```


```{r}
# create a histogram for the standard error measurements
ggplot(cancer_df[ , c(2,13:22)] %>% 
         pivot_longer(cols = radius_se:fractal_dimension_se), 
       aes(value, fill = diagnosis)) + 
    geom_histogram(bins = 10)  +  ggtitle("Histogram of Standard Error Measurements") +
  theme(plot.title = element_text(hjust = 0.5)) + 
    facet_wrap(~name, scales = 'free_x')
```

```{r}
# create a histogram for the maximum/worst measurements
ggplot(cancer_df[ , c(2,23:32)] %>% 
         pivot_longer(cols = radius_worst:fractal_dimension_worst), 
       aes(value, fill = diagnosis)) + 
    geom_histogram(bins = 10)  +  ggtitle("Histogram of Maximum/Worst Measurements") +
  theme(plot.title = element_text(hjust = 0.5)) + 
    facet_wrap(~name, scales = 'free_x')
```


Based on the output above, we chose to focus on the mean measurements.  The standard error and maximum/worst measurements do not add appear to add much over what is already visible in the mean measurements.


```{r hist1, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the Mean Radius of nuclei
ggplot(data = cancer_df, aes(x = radius_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Mean Radius of nuclei') 

ggplot(cancer_df, aes(x = radius_mean, color = diagnosis, fill = diagnosis)) + 
 geom_histogram(aes(y=..density..), alpha=0.5, 
                position="identity")+
 geom_density(alpha=.2)
```


```{r hist2, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the texture_mean
ggplot(data = cancer_df, aes(x = texture_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Texture Mean of nuclei') 
```

```{r hist3, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the perimeter_mean
ggplot(data = cancer_df, aes(x = perimeter_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Mean of nuclei perimeter') 
```


```{r hist4, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the area_mean
ggplot(data = cancer_df, aes(x = area_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Mean Area of nuclei') 
```

```{r hist5, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the smoothness_mean
ggplot(data = cancer_df, aes(x = smoothness_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Smoothness Mean of nuclei') 
```

```{r hist6, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the compactness_mean
ggplot(data = cancer_df, aes(x = compactness_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Compactness Mean of nuclei') 
```

```{r hist7, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the concavity_mean
ggplot(data = cancer_df, aes(x = concavity_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Concavity Mean of nuclei') 
```

```{r hist8, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the concave points_mean
ggplot(data = cancer_df, aes(x = `concave points_mean`)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Concave Points Mean of nuclei') 
```

```{r hist9, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the symmetry_mean
ggplot(data = cancer_df, aes(x = symmetry_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Symmetry Mean of nuclei') 
```

```{r hist10, warning=FALSE, error=TRUE, message=FALSE}
#Histogram of the symmetry_mean
ggplot(data = cancer_df, aes(x = fractal_dimension_mean)) + 
  geom_histogram(aes(fill = diagnosis), alpha = 0.5) +
  xlab('Fractal Dimension Mean of nuclei') 
```

```{r ggally, warning=FALSE, error=TRUE, message=FALSE}
library(GGally)

#Pair plot between variables
ggpairs(cancer_df[ , c(3:12)])
```



# 3. Split the data into test and training data.

```{r}
# First, rescale the data
# create the rescaling function we have been using thus far
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}
# create a copy of the df
rescaled_df <- cancer_df
# retain only the first two columns and all the 'mean' data
rescaled_df <- rescaled_df[1:12]
# apply the rescale function to all columns except id and diagnosis
rescaled_df[3:12] <- sapply(rescaled_df[3:12],rescale_x)
# confirm rescaling worked correctly
# all rescaled vars should be within [0,1]
summary(rescaled_df)

# Now split the data
# set the seed to Notre Dame's founding year
set.seed(1842)
# determine the number of rows in the dataframe
n <- nrow(rescaled_df)
# get a list of 20% of the rows in combined to use as indices
test_idx <- sample.int(n, size = round(0.2 * n))
# set the the training data to be those rows not matching the index list
training <- rescaled_df[-test_idx,]
# show the number of training rows
nrow(training)
glimpse(training)
# set the the test data to be those rows matching the index list
testing <- rescaled_df[test_idx,] 
# show the number of test rows
nrow(testing)
glimpse(training)
```





# 6. Build a classification algorithm using Kth Nearest Neighbors. Tune the value of K appropriately.
```{r}
# Choose a value for K that is equal to the square root of n,
# the numnber of onservations in the training set
k_try = sqrt(nrow(training[3:12]))
k_try

# We'll use 21 as our value of K
diag_knn_9 <- knn(training[3:12],testing[3:12],cl=training$diagnosis,k=21)

### Note to Avisek and Kait - we should pick either option 1 or two below
### Option 2 adds more information, but I don't know if it is useful
### I would like your feedback


### Option 1
cat("\n*** Option 1 ***\n")
# create and display the confusion matrix
confusion_1 <- table(diag_knn, testing$diagnosis)
confusion_1
# show the accuracy of the KNN classification
sum(diag(confusion_1)/nrow(testing))


### Option 2
cat("\n*** Option 2 ***\n")
# create and display the confusion matrix
confusionMatrix(factor(diag_knn),factor(testing$diagnosis))
```


Let's tune K to see if we can get better accuracy
```{r}
# set the seed for consistent results
set.seed(1842)
# set the train control to use 5-fold cross validation
# choosing 5-fold as a good middle ground
trControl <- trainControl(method  = "cv",
                          number  = 5)

#find the best knn fit using values of K of all odd numbers from 1 to 99
knn_fit <- train(diagnosis ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = c((1:50)*2 - 1)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = training[-1])
knn_fit
```


Revising our solution to use K = 9
```{r}
# We'll use 9 as our value of K
diag_knn_9 <- knn(training[3:12],testing[3:12],cl=training$diagnosis,k=9)
confusion_2 <- table(diag_knn_9, testing$diagnosis)
confusion_2
# show the accuracy of the KNN classification
sum(diag(confusion_2)/nrow(testing))

```
